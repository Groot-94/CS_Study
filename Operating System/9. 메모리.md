# 메모리
> 메인 메모리, RAM을 뜻한다. 


> 프로그램 실행 시 필요한 주소, 정보들을 저장하고 가져다 사용할 수 있게 만드는 공간

## 메모리 관리가 필요한 이유
> 각각의 프로세스는 독립된 메모리 공간을 갖고, 운영체제 혹은 다른 프로세스의 메모리 공간에 접근할 수 없는 제한이 걸려있다.


> 단지, 운영체제만이 운영체제 메모리 영역과 사용자 메모리 영역의 접근에 제약을 받지 않기 때문에 운영체제에서 메모리를 관리한다. 

## 운영체제의 역할
실행 파일이 로더에 의해 메모리에 올라오고 운영체제는 이 실행파일을 메모리의 어느 위치에 올릴지를 결정함

## 논리적 주소 vs 물리적 주소
- 논리적 주소(Logical address)
    - 프로세스마다 독립적으로 가지는 주소 공간
    - 각 프로세스마다 0번지부터 시작
    - CPU가 보는 주소는 논리적 주소임
    - 가상 주소
- 물리적 주소(Physical address)
    - 메모리에 실제 올라가는 위치
    - 보통 메모리의 낮은 주소 영역에는 운영체제가 올라가고, 높은 주소 영역에는 사용자 프로세스가 올라간다. 

## 주소 바인딩

> 프로세스의 논리적 주소를 물리적 메모리 주소로 연결하는 작업

`Symbolic Address` -> `Logical Address` -> `Physical Address`

- Symbolic Address란 말 그대로 상징적인 부분을 의미한다. 우리가 실제로 프로그래밍할 때 숫자로 된 메모리 주소에 변수를 할당하는 것이 아니라 어떤 변수명에 할당하는 것과 같다. 

- 주소 바인딩 방식은 프로그램이 적재되는 물리적 메모리의 주소가 결정되는 시기에 따라 세 가지로 분류할 수 있다.


## 1. Compile time binding
- `컴파일할 때` 물리적인 메모리 주소를 부여한다.
- 컴파일러는 절대 코드를 생성한다.
- 만약 시작 위치를 변경하고 싶다면 다시 컴파일 해야한다.
- 초기에 컴파일되어 생긴 logical address가 곧 physical address가 되기 때문에 다시 컴파일 해야만 물리적인 메모리 위치를 변경할 수 있다. 
## 2. Load time binding
- `실행할 때` 물리적인 메모리 주소를 부여한다.
- Loader의 책임 하에 물리적 메모리 주소가 부여되며 프로그램이 종료될 때까지 물리적 메모리 상의 위치가 고정된다.
    - Loader는 사용자 프로그램을 메모리에 적재하는 프로그램이다.
- 컴파일러가 재배치 가능한 코드를 생성한다. 
- 실행시 메모리 위치가 비어있기만 하면 해당 위치에 배치될 수 있다.

## 3. Run time binding(= Execution time binding)
- 프로그램이 실행 시작된 이후에도 프로세스의 메모리 상 위치를 옮길 수 있음
- CPU가 주소를 참조할 때마다 해당 데이터가 물리적 메모리의 어느 위치에 존재하는지 확인해야 하는데, 이때 주소 매핑 테이블(MMU)을 사용한다.
    - MMU는 논리적 주소를 물리적 주소로 매핑하는 하드웨어 장치이다.
- 기준 레지스터, 한계 레지스터 등과 같은 하드웨어적인 자원이 필요하다.

![](https://i.imgur.com/S7jNMyx.png)

위에서 소스코드는 Symbolic Address에 해당한다. A와 B를 더한 뒤 C로 이동하라는 의미이다.
이제 컴파일이 되면 논리적인 주소가 부여된다. 이제부터 앞서 이야기 했던 세 가지 주소 바인딩 방식에 따라 그림이 나뉘게 된다. 

먼저 compile time binding인 경우, 컴파일 시점에 이미 물리적인 메모리 주소가 결정된다. 즉, 이미 결정되어 있는 주소인 논리적인 주소가 물리적인 주소가 되는 것이다. 따라서 다른 주소가 비어있어도 해당하는 위치에만 올려야 한다는 비효율적인 측면이 있기 때문에 현재에는 사용하지 않는 방식이다.

load time binding은 프로그램이 시작되고 메모리에 올라갈 때 물리적인 메모리 주소가 정해지는 방식이다.

Run time binding은 실행 시에 주소가 결정되는 것은 load time binding과 동일하나, 이 주소는 실행 도중에 바뀔 수 있다. 예를 들어 원래 300번이었는데, CPU를 잠깐 뺏겼다가 다시 돌려받을 때 다시 메모리에 올라오게 되는데 이 때 기존의 300번이 아니라 600번에 할당될 수 있다는 것이다.

## Memory-Management Unit(MMU)
> MMU란 `logical address`를 `physical address`로 매핑해주는 하드웨어이다. 앞서 본 것처럼 run time binding을 위해 필요한 하드웨어이기도 하다.

- MMU Scheme 
    - 사용자 프로세스가 CPU에서 수행되며 생성해내는 모든 주소값에 대해 base register의 값을 더한다.
![](https://i.imgur.com/LsT3HnW.png)

중간에 보이는 relocation register/limit register로 총 2개의 레지스터로 작동하게 된다.

우선 CPU에서 논리 주소 346에 해당하는 값을 얻으려고 한다면, relocaion register가 14000만큼 기본 값을 더해서 물리적인 주소를 얻어낸다. 이에 14346의 위치를 확인하고 물리적인 메모리에서 값을 얻어 전달해준다.

만약 CPU가 요청한 논리주소 값과 relocation register 값의 합이 물리적인 메모리의 범위를 넘어서면 어떻게 될까?
이는 논리주소를 범위에서 벗어난 더 큰 요청을 한 것과 같다고 볼 수 있는데, 이는 limit register에서 검사해준다.

![](https://i.imgur.com/osPQxXN.png)

만약 범위를 넘어서면 trap이 걸리고, CPU 제어권이 운영체제로 넘어가게 된다. 그러면 CPU는 원인을 파악하게 된다. 아무 문제가 없다면 그대로 기본값을 더해서 물리적인 주소를 찾게 되는 것이다.

따라서 사용자 프로그램은 논리주소만을 다루며, 실제 물리주소를 볼 수 없고 알 필요도 없다.
MMU가 알아서 주소 변환을 해서 알려주기 때문이다.

## 메모리 관리와 관련된 용어
## 3. Dynamic Loading(= 동적 로딩)
> 프로세스 전체를 메모리에 미리 다 올리는 것이 아니라 해당 루틴이 불려질 때 load하는 것이다. 

- 따라서 필요한 부분만 메모리 공간을 차지하기 때문에 memory utilization이 향상된다.
- 운영 체제의 특별한 지원 없이 프로그램 자체에서 구현 가능하다.

## 4. Overlays
> 메모리에 프로세스의 부분 중 실제 필요한 정보만을 올리는 기법이다.

초창기 컴퓨터 시스템에서 물리적 메모리의 크기 제약으로 인해 하나의 프로세스조차도 메모리에 한꺼번에 올릴 수 없을 때, 프로세스의 주소 공간을 분할해서 당장 필요한 일부분을 메모리에 올려 실행하고 해당 부분에 대한 실행이 끝난 후에 나머지 부분을 올려 실행하는 기법을 뜻한다.

- 정의만 볼 때 dynamic loading과 같은 역할을 하는 것처럼 보인다.
- 하지만 위의 예시처럼 dynamic loading과 달리 overlay는 프로세스의 크기가 메모리보다 클 때 유용하게 사용할 수 있는 방식이다.
- 프로세스의 크기가 메모리보다 클 때 유용
- 운영체제의 지원없이 사용자에 의해 구현

> 동적 로딩과의 차이점
- 동적 로딩: 다중 프로세스 환경에서 메모리에 더 많은 프로세스를 동시에 올려놓고 실행하기 위한 용도
- 오버레이: 단일 프로세스만을 메모리에 올려놓는 환경에서 메모리 용량보다 큰 프로세스를 올리기 위한 어쩔 수 없는 선택

## 5. Swapping
프로세스 전체를 일시적으로 메모리에서 backing store로 쫓아내는 것이다. 여기서 backing store란 swap area를 말하기도 하며, 디스크를 의미한다고 봐도 무방하다. 하드 디스크처럼 큰 저장 공간을 의미하는 것이다.

Swapping은 프로세스 라이프 사이클을 다룰 때도 봤을 것이다. 프로세스가 suspend 될 때 swap-out이라고 하고 다시 복구할 때를 swap-in이라고 했다.
프로세스가 너무 많을 경우 일반적으로 중기 스케줄러(swapper)에 의해 swap-out 시킬 프로세스를 선정한다.
- priority-based CPU scheduling algorithm
    - priority가 낮은 프로세스를 swap-out
    - priority가 높은 프로세스를 메모리에 올림

또한 compile time 혹은 load time binding에서는 swap-out당한 프로세스는 원래 메모리 위치로 swap-in 해야한다. 이 경우 swapping의 효율성을 100% 발휘하기가 어렵다. 

## 6. Dynamic Linking(= 동적 연결)
> 연결(linking)이란 프로그래머가 작성한 소스 코드를 컴파일하여 생성된 목적 파일(object file)과 이미 컴파일된 라이브러리 파일들을 묶어 하나의 실행 파일을 생성하는 과정이다.

> 동적 연결은 컴파일을 통해 생성된 목적 파일과 라이브러리 파일 사이의 연결을 프로그램의 실행 시점까지 지연하는 기법

- Static linking(= 정적 연결)
    - 라이브러리가 프로그램의 실행 파일 코드에 포함된다
    - 실행 파일의 크기가 커진다
    - 동일한 라이브러리를 각각의 프로세스가 메모리에 올리므로 메모리 낭비이다
- Dynamic linking(= 동적 연결)
    - 라이브러리가 실행시 link된다.
        - linking을 실행 시간까지 미루는 것이다.
    - 라이브러리 호출 부분에 라이브러리 루틴의 위치를 찾기 위한 stub라는 작은 코드를 둠
    - 라이브러리가 이미 메모리에 있으면 그 루틴의 주소로 가고 없으면 디스크에서 읽어옴
    - 운영체제의 도움이 필요

## 7. Allocation of Physical Memory(= 물리적 메모리의 할당 방식)

메모리는 일반적으로 두 영역으로 나뉘어 사용된다.

- OS 상주 영역
    - 인터럽트 벡터와 함께 낮은 주소 영역 사용
- 사용자 프로세스 영역
    - 높은 주소 영역 사용
    
사용자 프로세스 영역의 할당 방법에는 두 가지가 있다.

- Contiguous allocation(= 연속 할당)
    - 하나의 프로세스를 연속적으로 저장하는 기법으로, 프로세스의 시작 주소만 알면 된다.
    - 통째로 올라가는 것과 유사하다.
    - 고정 분할 방식과 가변 분할 방식이 존재한다.
- Noncontiguous allocation(= 불연속 할당)
    - 하나의 프로세스가 메모리의 여러 영역에 분산되어 올라갈 수 있다.
    - Paging, Segmentation, Paged Segmentation 방식이 존재한다.


## 8. Contiguous allocation(= 연속 할당)

Contiguous allocation에는 두 가지 경우가 있다. 

- Fived partition(고정 분할 방식)
    - 물리적 메모리를 몇 개의 영구적인 파티션으로 나눈다.
    - 파티션당 하나의 프로세스를 적재해 실행한다.
    - 동시에 메모리에 올라가는 프로그램의 수가 고정되고, 최대 수행 가능 프로그램의 크기가 제한되는 점에서 유연하지 못하다.
    - 외부 조각과 내부 조각이 발생할 수 있다.
        - 외부 조각: 프로그램의 크기보다 파티션의 크기가 작은 경우 해당 파티션이 비어있는 데도 불구하고 프로그램을 적재하지 못하기 때문에 생기는 메모리 공간을 의미한다.
            - 내가 올리려는 프로그램보다 메모리 크기가 작다.
        - 내부 조각: 프로그램의 크기보다 파티션의 크기가 큰 경우 해당 파티션에 프로그램을 적재하고 남는 메모리 공간을 의미한다.
            - 내가 올리려는 프로그램보다 메모리 크기가 크다.


- Variable partition(가변 분할 방식)
    - 프로그램의 크기를 고려해서 할당한다.
    - partition의 크기, 개수가 동적으로 변한다.
    - 고정 분할 방식과 달리 미리 메모리 영역을 나누어 놓지 않는다.
    - 프로그램이 실행될 때마다 차곡차곡 메모리에 올리므로 내부 조각이 발생하지 않는다.
        - 다만 중간에 프로그램이 종료되어 메모리에서 빠져 나가고, 그 공간에 새로운 프로그램이 메모리에 할당될 경우 외부 조각이 발생할 수 있다.
![](https://i.imgur.com/w9Dyfg7.png)

그림에서 `고정 분할 방식`으로 보면, 프로그램 B는 분할2보다 작기 때문에 들어가지 못하고 분할3에 할당된 것을 볼 수 있다.
따라서 분할2는 외부 조각이 되고, 분할3에서 남은 공간은 내부 조각이 된다. 이는 낭비되는 조각이다.

`가변 분할 방식`은 프로그램이 실행될 때마다 메모리에 올려두게 된다. 만약 B가 끝나게 되면 B의 공간이 비게 되는데 이 때 D의 크기는 B의 크기와 다르다고 가정해보자. 그렇다면 기존 B의 공간에는 D가 들어가지 못하고 아래 부분에 들어가게 되며, 기존 B의 공간은 외부 조각이 되는 것이다.

이렇게 가변 분할 방식에서 발생하는 빈 공간을 Hole이라고 한다. Hole은 말 그대로 가용 메모리 공간을 의미하며 다양한 크기의 Hole들이 메모리의 여러 곳에 흩어져 있을 수 있다. 프로세스가 도착하면 아래 그림처럼 수용 가능한 hole에 할당된다.

따라서 운영체제의 어디가 비어있고, 어디가 사용 중인지 계속 알고 있어야 하기 때문에 할당 공간과 가용 공간(Hole)에 대한 정보를 유지하고 있어야 한다.

![](https://i.imgur.com/ZSWWXt8.png)

그렇다면 어떤 Hole에 할당하는 것이 가장 최선의 방법일까? 이런 문제를 `dynamic storage-allocation problem`이라고 하며, 가변 분할 방식에서 size가 n인 요청을 만족하는 가장 적절한 Hole을 찾는 것이 목적이다.

- First-fit
    - 사이즈가 n이상인 것 중 최초로 찾아진 hole에 할당함
- Best-fit
    - 사이즈가 n이상인 가장 작은 hole을 찾아서 할당함
    - hole들의 리스트가 크기순으로 정렬되지 않은 경우 모든 hole의 리스트를 탐색해야만 함
    - 많은 수의 아주 작은 hole들이 생성됨
        - n 이상이긴 하나 차이가 근소하기 때문에 그만큼의 작은 hole들이 생김

실험 결과로는 first-fit과 best-fit이 worst-fit보다 속도와 공간 이용 측면에서 효과적인 것으로 알려져 있다. first-fit의 경우 적당한 hole을 찾는 overhead가 적을 것이고, best-fit의 경우 적당한 hole을 찾게 된다면 미래에 좋을 것이다.

이외에도 외부 조각 문제를 해결하기 위한 `compaction`이라는 것이 있다.

- Compaction
    - 외부 조각 문제를 해결하는 한가지 방법
    - 사용 중인 메모리 영역을 한 군데로 몰고 hole들을 다른 한 곳으로 몰아 큰 block을 만드는 것
    - 매우 비용이 많이 드는 방법이다
    - 최소한의 메모리 이동으로 compaction을 하는 것은 매우 복잡한 문제이다
    - 또한 compaction의 경우 프로세스의 주소가 실행 시간에 동적으로 재배치가 가능한 경우에만 수행될 수 있다.
        - 왜냐하면 사용 후 남은 메모리를 동적으로 관리해야하기 때문에 재배치가 가능하다는 가정이 있어야 한다.

## 8. Noncontiguous allocation
지금까지 contiguous allocation 방법에 대해 알아봤지만, 사실 현대의 방식에서는 Noncontiguous allocaion 방법이 사용된다. 따라서 위의 문제들로부터 자유로운 편이다.

=> Paging



---

# Virtual Memory 2 

## 캐슁 기법 
- 한정된 빠른 공간(=캐쉬)에 요청된 데이터를 저장해 두었다가 후속 요청시 캐쉬로부터 직접 서비스하는 방식
- paging system 외에도 cache memory, buffer caching, web caching 등 다양한 분야에서 사용

## Page Frame의 Allocation
지금까지는 메모리에 여러 프로그램이 올라와 있었다. 하지만 실제로는 어떤 프로그램이 원활하게 실행이 되기 위해서는 일련의 페이지들이 메모리에 같이 올라와있어야 더 효율적이다.
loop를 구성하는 페이지들은 한 번에 allocate되는 것이 유리하다. 최소한의 allocation이 없으면 매 loop마다 page fault가 발생하기 때문이다.

한 프로그램이 메모리를 독차지하게 되면, 다른 프로그램이 메모리에 올라와 있지 못해 비효율적이게 된다. 즉, allocation은 `하나의 프로그램에 어느 정도의 메모리 페이지를 나누어 주는 것을 보장`하는 역할을 한다. 

- Allocation problem: 각 process에 얼마만큼의 page frame을 할당할 것인가에 대한 문제이다.

- Allocation의 필요성
    - 메모리 참조 명령어 수행시 명령어, 데이터 등 여러 페이지 동시 참조
        - 명령어 수행을 위해 최소한 할당되어야 하는 frame의 수가 있음
    - Loop를 구성하는 page들은 한꺼번에 allocate 되는 것이 유리함
        - 최소한의 allocation이 없으면 매 loop마다 page fault

- 페이지 프레임 할당 알고리즘
    - 균등 할당(Equal Allocation): 모든 프로세스에게 페이지 프레임을 균일하게 할당
    - 비례 할당(Proportional Allocation): 프로세스의 크기에 따라 페이지 프레임을 비례하여 할당
    - 우선순위 할당(Priority Allocation): 프로세스의 우선순위에 따라 페이지 프레임을 할당
        - 당장 CPU에서 실행될 프로세스와 그렇지 않은 프로세스를 구분

## Global vs Local Replacement
어떤 프로그램이 메모리를 많이 필요로 하면 그 때는 해당 프로그램의 메모리가 많이 올라와서 다른 프로그램의 페이지가 쫓겨날 수도 있다. 

이때 굳이 미리 할당하지 않고, 알아서 알고리즘에 의해 프로세스별로 메모리 할당량이 바뀌도록 하는 것이 global replacement이다.

## Global replacement(= 전역 교체)
- replace될 때, 다른 프로세스에 할당된 frame을 뺏을 수 있다.
    - 즉, 모든 페이지 프레임이 교체 대상이 될 수 있는 방법이다. 

- 전체 메모리를 각 프로세스가 공유해서 사용하고, 교체 알고리즘에 근거해서 할당되는 메모리 양이 가변적으로 변하는 방법이다.
    - 페이지 교체 시 다른 프로세스의 프레임을 빼앗아 올 수 있으므로 프로세스별 프레임 할당량을 조절할 수 있게 된다.
- FIFO, LRU, LFU등의 알고리즘을 global replacement로 사용할 수 있음
- Working Set, PFF 알고리즘을 global replacement로 사용할 수 있음

## Local replacement(= 지역 교체)
- 자신에게 할당된 페이지 프레임 내에서만 교체한다.
- FIFO, LRU, LFU 등의 알고리즘을 지역 교체로 사용할 수 있다.

## Thrashing
- 최소 메모리도 할당이 안됐을 때는 page fault가 일어난다고 했었다. 이러한 상황을 `Thrashing`이라고 한다.
- ![](https://i.imgur.com/AoTGhzG.png)

x축은 cpu가 놀지 않고 일하는 시간, y축은 프로그램 개수
10개 프로그램중에 9개가 i/o를 하러 가더라도 남은 1개의 프로그램이 cpu를 쓰면 되기 때문에

그래서 일반적으로 degree of multiprogramming을 올려주면 cpu utilization도 올라간다.
하지만 프로그램 개수를 계속 늘리다보면 Thrasing이 발생한다.

> 스레싱이 발생하는 시나리오
- OS는 CPU 이용률이 낮을 경우 메모리에 올라와 있는 프로세스의 수가 적다고 판단하여 메모리에 올라가는 프로세스를 늘린다. (CPU 이용률이 낮으면 MPD를 높인다.)
    - 준비 큐에 프로세스가 단 하나라도 있으면 CPU는 그 프로세스를 실행하므로 쉬지 않고 일하게 되는데, CPU 이용률이 낮다는 것은 준비 큐가 비어있다는 것을 뜻한다.
    - 메모리에 동시에 올라가 있는 프로세스의 수를 다중 프로그래밍의 정도(MPD)라고 부른다.
- MPD가 과도하게 높아지면 각 프로세스에게 할당되는 메모리의 양이 지나치게 감소한다.
- 각 프로세스는 그들이 원활하게 수행되기 위해 필요한 최소한의 페이지 프레임도 할당 받지 못하므로 페이지 부재율이 급격히 증가한다.
- 페이지 부재가 발생하면 I/O 작업을 수반하므로 다른 프로세스에게 CPU가 넘어간다.
- 다른 프로세스 역시 페이지 부재가 발생하고 있어서 또 다른 프로세스에게 CPU가 넘어간다.
- 결국 준비 큐에 있는 모든 프로세스에게 CPU가 한 차례씩 할당 되었는데도 모든 프로세스가 다 페이지 부재를 발생하여 CPU의 이용률이 급격하게 떨어진다.
- OS는 위 현상이 메모리에 MPD가 낮다고 판단하여 MPD를 높이려고 한다.

위 악순환이 계속 반복되는 상황을 스레싱이라고 부른다.

> 위의 문제때문에 이걸 해결하는 알고리즘(Working set, PFF)이 등장함

## Working-Set Model
- Locality of reference (= 참조의 지역성)
    - 프로세스는 특정 시간 동안 일정 장소만을 집중적으로 참조한다.
    - 집중적으로 참조되는 해당 page들의 집합을 locality set이라 함
- Working-set Model
    - Locality에 기반하여 프로세스가 일정 시간 동안 원활하게 수행되기 위해 한꺼번에 메모리에 올라와 있어야 하는 page들의 집합을 `Working Set`이라 정의함
    - Working Set 모델에서는 process의 working set 전체가 메모리에 올라와 있어야 수행되고, 그렇지 않을 경우 모든 frame을 반납한 후 swap out
        - 다 보장해주지 못하면 아예 포기해버린다는 것이다.
        - Multiprogramming degree를 조절하여 Thrashing을 방지함

## Working-Set Algorithm
![](https://i.imgur.com/5NKOToK.png)

- 과거를 통해 working set을 추정한다.
- 예를 들어 그림처럼 10의 시간만큼 해당하는 page들을 보면 {1,2,5,6,7}이 해당되는 것을 볼 수 있다. 이것이 working set이 되며, working set 알고리즘은 5개의 페이지 프레임을 줄 수 있으면 {1,2,5,6,7}을 메모리에 올려둔다. 상황이 안된다면 swap out하는 것이다.

다른 말로 이해해보면, 참조된 후 Δ 시간 동안 해당 page를 메모리에 유지한 후 버린다고도 볼 수 있다.

- 윈도우 사이즈 Δ
    - 워킹셋을 제대로 탐지하기 위해서는 윈도우 사이즈를 잘 결정해야 한다.
    - Δ 값이 너무 작으면 지역셋을 모두 수용하지 못할 수 있다.
    - Δ 값이 너무 크면 여러 규모의 지역셋을 수용할 수 있다.
    - Δ 값이 무한대이면 전체 프로그램을 구성하는 페이지를 워킹셋으로 간주한다.
    
## PFF(Page Fault Frequency) Scheme
![](https://i.imgur.com/6dKgQ3S.png)


직접 page fault rate(= 페이지 부재율)를 살펴보며 행동하는 방식이다. 기본적으로 page fault rate의 상한값/하한값을 두게 된다.

- page fault rate가 상한값을 넘으면 frame을 더 할당한다.
- page fault rate가 하한값 이하이면 할당 frame 수를 줄인다.

비어있는 frame이 없다면, 즉 줄 수 있는 frame이 없다면 일부 프로세스를 swap out 시켜서 trashing을 방지하게 된다.



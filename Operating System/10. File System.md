# 10. File System

# File System
## File & File System

### File
- **이름**을 통해 접근하는 단위
    - 메모리는 **주소**를 통해 접근
- 비휘발성의 보조기억장치에 저장
    - ex) 하드디스크
- 단순 데이터 저장뿐만 아니라 다양한 저장 장치를 file(device special file)이라는 논리적 단위로 저장하기도 함
- 파일로 정의되는 연산(operation)
    - 종류: create, read, write, reposition(lseek), delete, open, close...
        - reposition(lseek)
            - 파일의 seek pointer(커서)를 조정
            - 특정 위치부터 읽거나 쓰고싶을때 유용
        - open
            - read, write 이전 선행.
            - 파일을 디스크에서 메모리로 내용을 올려놓는게 아님
            - **파일의 메타데이터**를 메모리에 올려놓는 작업

### File attribute(File metadata)
- 파일 자체 정보말고 파일을 관리하기 위한 각종 정보들
    - 파일 이름, 유형, 저장된 위치, 파일 사이즈
    - 접근 권한(읽기/쓰기/실행), 시간(생성/변경/사용), 소유자 등

### File System
- 운영체제에서 파일을 관리하는 부분
- 파일 및 파일의 메타데이터, 디렉토리 정보 등 관리
- 파일의 저장 방법 결정
- 파일 보호 등
- 파일 시스템 또한 하드디스크에 저장

## Directory & Logical Disk
### Directory
- 파일의 메타데이터 중 일부를 보관하는 일종의 특별한 파일
- 해당 디렉토리에 속한 파일 이름 및 파일 attribute들
- operation
    - search for a file, create a file, delete a file
    - list a directory, rename a file, traverse the file system(파일시스템 전체 탐색)

> #### File vs File attribute(metadata) vs Directory
```
음악 파일 
    - 음악 내용
    
음악 파일 메타데이터 
    - 파일의 이름, 접근권한, 디렉토리 파일 이름, 디렉토리 파일 접근권한 등

디렉토리 파일 
    - 디렉토리 파일 밑에 존재하는 파일들이 어떤 것인지
    - 디렉토리 밑에 있는 파일의 메타데이터를 내용으로 하는 파일
    - 디렉토리에 파일의 메타데이터를 모두 저장할 수 있지만, 일부 메타데이터는 디렉토리에 저장하고, 나머지 메타데이터는 다른곳에 저장하기도 함
    - 다른 파일과 구별할 수 있는 최소한의 일부 속성을 담고 있을 뿐 상세한 데이터가 담겨 있지 않음
    - 즉, 실제 데이터가 있는 파일이 담겨져 있는 것이 아니라 하위 디렉토리나 파일의 구조화된 속성 정보(위치 등)만을 담아 해당 하위 디렉터리 또는 파일을 연결해주는 매개체
```

### Partition(=Logical Disk)
- 디스크는 논리 디스크와 물리적 디스크가 있는데, 운영체제가 보는 디스크는 논리 디스크(Partition)
    - 하드 디스크를 하나 사서, C드라이브, D드라이브 나누면, 그 각각이 논리 디스크가 됨
- 하나의 (물리적) 디스크 안에 여러 파티션을 두는게 일반적
- 여러 개의 물리적인 디스크를 하나의 파티션으로 구성하기도 함
- (물리적) 디스크를 파티션으로 구성한 뒤 각각의 파티션에 file system을 깔거나 swapping 등 다른 용도로 사용할 수 있음
    - swapping 용도 = 논리 디스크를 virtual memory swap area로도 사용가능하다는 의미
    - 그래서 보통 디스크를 file area 용도, swap area용도로 나누어 봄

## open()
### 간단분석
<img src="https://i.imgur.com/XUsOJ01.png" width="600" height="500">

- 파일의 메타데이터를 메모리로 올려놓는 연산
- 논리 디스크안에 파일 시스템이 있으면, 그 파일 시스템에 특정 파일의 메타데이터도 저장되어 있고, 그 파일의 내용도 저장되어 있을 것임
    - 메타데이터 중에 파일의 저장 위치도 존재
    - 파일의 내용을 가리키는 포인터도 저장됨
- 파일을 open()하게 되면, 그 파일의 메타데이터가 메모리에 올라오게 됨 
    - 예시) open("/a/b/c")
        - 디스크로부터 파일 c의 메타데이터를 메모리로 가지고 옴
        - 이를 위하여 directory path를 search
            - 루트 디렉토리 "/"를 open하고, 그 안에서 파일 "a"의 위치 획득
            - 파일 "a"를 open한 후, read하여, 그 안에서 파일 "b"의 위치 획득
            - 파일 "b"를 open한 후, read하여, 그 안에서 파일 "c"의 위치 획득
            - 파일 "c"를 open한다
        - Directory path의 search에 너무 많은 시간 소요
            - Open을 read/write와 별도로 두는 이유
            - 한번 open한 파일은 read/write 시 directory search 불필요
        - Open file table
            - 현재 open된 파일들의 메타데이터 보관소(in memory)
            - 디스크의 메타데이터보다 몇 가지 정보가 추가
                - Open한 프로세스의 수
                - File offset: 파일 어느 위치 접근 중인지 표시(별도 테이블 필요)
        - File descriptor(file handle, file control block)
            - Open file table에 대한 위치 정보(프로세스 별)

### 심화분석

<img src="https://i.imgur.com/15ncdZj.png" width="600" height="500">

- 좌측: 물리적 메모리 / 우측: 논리적 디스크
- open 실행 과정
    - 탐색
        ```
        - 사용자 프로그램이 시스템 콜
        - CPU 제어권이 운영체제로 넘어감
        - 운영체제안에는 각 프로세스 별로 관리하기 위한 자료구조(PCB) 존재
        - 전체 프로그램들이 Open한 파일들이 어떤 건지 관리해주는 글로벌한 테이블(Open file table) 존재
        - root directory의 metdata는 이미 알려져 있음
        - 고로 운영체제가 root directory의 metadata가 어디있는지 앎
        - root directory의 metadata를 먼저 메모리에 올림(root를 먼저 open)
        - metadata에는 파일의 위치정보가 있음
        - 즉, root 데이터의 실제 내용이 어디 있는지 위치를 찾을 수 있음
        - root는 디렉토리 파일이므로, 내용은 디렉토리 밑에 있는 파일들의 메타데이터를 가지고 있음
        - 이때문에 root 디렉토리의 내용에는 a디렉토리(파일)의 메타데이터가 있을 것임
        - 이또한 메모리에 올려놓음(a open)
        - a 메타데이터에는 a의 파일시스템상 위치정보 존재
        - 이를 살펴보면, a가 디스크 어디에 위치하는지 알 수 있음
        - a 또한 디렉토리 파일이니, 하위 디렉토리 파일에 대한 메타데이터 존재
        - 따라서, a 디렉토리 파일 안에는 b라는 파일에 대한 메타데이터 존재
        - 이걸 찾아, 메모리에 다시 올려놓음(b open)
        - open은 그 파일의 메타데이터를 메모리에 올려놓는 작업이 이를 의미
        ```
    - 결과 반환
        ```
        - open 종료시, 시스템 콜을 했기 때문에, 결과값을 return
        - 그 결과값은 각 프로세스마다 각 프로세스가 open한 파일들에 대한 메타데이터 포인터를 가지고 있는 일종의 배열이 정의되어 있음
        - b라는 파일의 메타데이터 위치를 가리키는 포인터가 배열 어딘가에 만들어지고, 이 배열에서 몇번째 index인지가 file descriptor가 되서 사용자 프로세스에게 리턴
        - 이제는 b라는 파일이 open되었기 때문에, b라는 파일이 어디있는지에 대하여 root directory부터 다시 탐색할 필요가 없어짐
        - b라는 파일의 메타데이터를 보면 나와있음
        - 그리고 b의 메타데이터는 이미 메모리에 올라와 있음
        - 메모리에 올라온 위치가 fire descriptor인데, 이를 가지고 있기 때문에 사용자 프로세스는 fire descriptor 숫자만 가지고, 즉 배열의 index만 가지고 read/write 요청 가능
        - 그래서 b라는 파일에 무언가를 읽어오고 싶을 때, read할 때 argument를 적는게 아니라, open한 다음에, fire descriptor를 적어주면 됨
        - read 또한 시스템 콜을 한 것이니, CPU가 운영체제로 넘어감
        - A 프로세서가 이런 file descriptor를 가지는 파일에서 무언가를 읽어오라고 요청했음
        - 그러면 A의 PCB에 가서 해당 descriptor에 대응하는 파일의 메타데이터 부분을 Open file table에서 따라 간 다음에, 이 파일의 위치정보가 disk 어디에 있는지 metadata에 적혀있으니, 시작위치부터 읽어올 것임
        - 그 내용을 읽어서 사용자 프로그램에 직접 전달하는 것이 아니라, 운영체제가 자신의 메모리 공간 일부에다가 먼저 읽어 놓고, 그 다음에, 사용자 프로그램에게 이를 copy해서 알려줌
        - 만약, 다른 프로그램이 동일한 파일의 동일한 위치를 요청(read systemcall)하면, disk까지 갈게 아니라, 운영체제에서 이미 읽어놓은 것이 있으니, 이를 바로 전달 가능
        - 이것이 바로 buffer cache
        ```

### 추가분석
#### buffer cache
- paging 기법에서 이미 메모리에 올라온 페이지에 대하여 운영체제가 중간에 끼어들지 못하고, 하드웨어가 주소 변환을 해가지고 접근을 바로 했고, page fault가 발생하면 그제서야 운영체제한테 CPU가 넘어가서 운영체제가 swap 영역에서 해당 page를 읽어왔음
- 파일 read/write 시스템에서는 역시 buffer cache라는 것을 운영체제가 가지고 있는데, 요청한 내용이 **buffer cache 안에 있든, 없든 운영체제한테 cpu 제어권이 넘어가게 됨**
    - 시스템 콜이기 때문에 운영체제에게 cpu 제어권이 넘어가게 되어 있음 
- 그래서 buffer cache환경에서는 LRU, LFU 알고리즘을 자연스럽게 사용 가능
    - 모든 정보를 운영체제가 다 알고 있기 때문
    - paging에서 LRU를 못쓰고, clock 알고리즘을 썼던 것과 대조가 됨

#### 커널이 유지하는 테이블
- ##### per-process file descriptor table
    - file descriptor table는 프로세스 마다 가지고 있다고 해서 이와 같이 부름
- ##### system-wide open file table
    - 시스템 전체에 하나 존재하는 Open file table
    - Open file table은 파일을 오픈했으면 프로세스마다 가지고 있는게 아니라, 오픈된 파일의 목록들을 system-wide하게 한꺼번에 관리
    - open file table이 global하게 존재하는게 하나 있고, 프로세스마다 별게로 존재하는 테이블이 따로 있음
        - 차이점으로 metadata가 디스크에 있을때는, 앞서 살펴본 파일 이름, 유형, 저장된 위치, 접근 권한 등등이 metadata가 되는데, 이걸 메모리에 올려놓게 되면, 추가적으로 한가지 metadata가 더 필요
        - 현재 프로세스가 이 파일의 어느 위치를 접근하고 있다는 offset을 같이 가지고 있어야함
        - 이는 프로세스마다 별도 보유
            - A라는 프로그램이 파일1을 오픈할 수 있지만, B라는 프로그램도 파일1 오픈할 수도 있음
            - 그러면 파일1의 메타데이터는 하나의 copy만 올라가 있을 것임
            - system-wide하게 하나만 존재하는데, offset은 다를 것임
                - A 프로그램이 파일1을 읽는 위치와, B 프로그램이 파일1을 읽는 위치가 상이할 수 있기 때문
            - 그래서 open file table은 또 2개로 나누어서, 프로세스와 무관하게 하나만 가지고 있으면 되는 것과, 프로세스가 어디로 접근하고 있는지 별도로 가져야하는 offset을 따로 관리하는 테이블을 두는게 일반적

## File Protection
### File Protection
- 파일의 접근권한
- 파일 보호와도 연관
- 각 파일에 대해 누구에게 어떤 유형의 접근(read/write/execution)을 허락할 것인가?
    - 메모리는 프로세스마다 별도로 가지고 있어 결국 자기 혼자밖에 보지 못함
    - 그래서 memory protection은 연산이 무엇이냐, write할 수있는 page냐, read만 할 수 있는 page냐 뿐
    - 반면, file protection은 파일은 여러 사용자, 여러 프로그램이 같이 사용 가능
    - 접근권한이 누구에게 있느냐, 접근 연산이 어떤게 가능하냐, 이 2가지를 가지고 있어야 함 
    
### Access Control 방법
- Access Control Matrix

    <img src="https://i.imgur.com/As4tIWC.png" width="500" height="100">
    
    - 파일은 본디 엄청 많고, 어떤 파일은 특정 사용자가 자신만 사용하려고 만든 경우, 이를 행렬로 표현하면 낭비가 될 수 있음 => Linked List로 행렬에 의한 공간 낭비 최소화
    - Linked List 주체가 file이면 Access Control List, 사용자 주체면 Capability (list)
        - Access control list: 파일별로 누구에게 어떤 접근권한이 있는지 표시
        - Capability: 사용자별로 자신이 접근 권한을 가진 파일 및 해당 권한 표시
- Grouping
    - 위의 linked list 방식도 그럼에도 overhead가 크기 때문에, 일반적인 운영체제는 grouping을 통해 파일의 접근 권한 제어
    - 전체 user를 owner, group, public의 세 그룹으로 구분
    - 각 파일에 대해 세 그룹의 접근 권한(rwx)을 3비트씩으로 표시
        - 즉, 파일 하나에 대하여 접근 권한을 나타내기 위해 9bit만 필요
    - 예시) UNIX

    <img src="https://i.imgur.com/VKoBQzK.png" width="200" height="100">


- Password
    - 파일마다 password를 두는 방법(디렉토리 파일에 두는 방법도 가능)
    - 모든 접근 권한에 대해 하나의 password: all-or-nothing
    - 접근 권한별 password: 암기 문제, 관리 문제

## File System의 Mounting
### File System의 Mounting

<img src="https://i.imgur.com/JisFdYe.png" width="600" height="400">

- 하나의 물리적인 disk를 partioning을 통해서 여러개의 논리적인 디스크로 나눔
- 각각의 논리적인 disk에는 file system을 설치해서 사용 가능
- root file system이라고 해서 특정 운영체제에 대해 file system 하나가 접근이 가능한데, 만약 다른 파티션에 설치된 file system에 접근해야 된다면, Mounting이라는 연산이 있음

<img src="https://i.imgur.com/q3UTt2R.png" width="600" height="400">

- Mounting은 root file system의 특정 디렉토리 이름에다 또 다른 파티션에 있는 file system을 가지고 mount를 해주면, 그 mount된 디렉토리로 접근하게 되면, 또 다른 file system의 root directory에 접근하는 꼴이 됨
- 이때문에, 서로 다른 파티션에 존재하는 file system에 접근할 수 있게 됨

## File 접근 방법
### Access Methods
- 시스템이 제공하는 파일 정보의 접근 방식
- 순차 접근(sequential access)
    - 카세트 테이프를 사용하는 방식처럼 접근
    - 읽거나 쓰면 offset은 자동적으로 증가
    - A->B->C 순서에서 A 다음 C를 보려면 B를 보는 작업 필수적
- 직접 접근(direct access, random access)
    - LP 레코드 판과 같이 접근하도록 함
    - 파일을 구성하는 레코드를 임의의 순서로 접근 가능
    - A->B->C 순서에서 A 다음 C를 보려면 B를 보는 작업 건너뛰기 가능
    - **직접 접근이 가능한 매체라 하더라도 데이터를 어떻게 관리하느냐에 따라, 순차접근만 허용하는 경우가 있고, 직접 접근이 가능한 경우가 있음**
    
# File System Implementation
## File 저장 방법(Allocation of File Data in Disk)
### Contiguous Allocation
- 특징

    <img src="https://i.imgur.com/cD1Iv9h.png" width="600" height="400">
    
    - 파일 크기는 균일하지 않음
    - 디스크에 파일 저장할 때는, 동일한 크기의 섹터(논리적인 블럭) 단위로 나누어 저장
    - 메모리의 페이징 기법과 유사
    - 연속 할당 방법
    - 하나의 파일이 디스크 상에 연속해서 저장되는 방법
    - 해당 예시에서는 하나의 디렉토리에 다섯가지 파일이 있고, 파일 이름, 파일 위치와 같은 메타데이터가 존재
- 장점
    - Fast I/O
        - 하드디스크의 접근시간은 거의 대부분 disk head가 이동하는 시간(크기는 많이 상관 X)
        - 한번의 seek/rotation으로 많은 바이트 transfer
        - file system 용도로는 Realtime file 용도 정도
        - 보통 file system 용도보다는 이미 run 중이던 prossee의 swapping 용
            - swapping은 file 저장이 아니라, 프로세스의 주소 공간 중 일부를 물리적인 메모리에서 쫓아내고, 나중에 필요할때 올려놓는 용도
            - file system은 영속적인 공간으로, 전원이 나가더라도 유지되어야 하는데, swap area는 그렇지 않음
            - swap이 끝나면 의미가 없는 정보. 임시로 저장해놓기만!
            - 공간 효율성 보다는 시간 효율성이 더욱 중요한 영역
    - Direct access(=random access) 가능
        - 19번 블럭에서 23번 블럭이 보고 싶다면, 20, 21, 22를 다 봐야하는게 아니라, 바로 숫자 4를 더해 23번으로 접근 가능
- 단점
    - 외부조각 발생 가능(external fragmentation)
    - File grow가 어려움
        - file은 크기가 중간중간 변할 가능성 농후
        - file 생성시 얼마나 큰 hole을 배당할 것인가?
        - grow 가능 vs 낭비 (internal fragmentation)
            - 내부조각은 현재 사용도 되고 있지 않은데 할당했기 때문에 낭비에 해당

### Linked Allocation
- 특징

    <img src="https://i.imgur.com/DNuI76H.png" width="600" height="400">
    
    - 연결 할당 방법
    - 하드디스크임에도 직접 접근이 불가
    - 파일의 시작위치만 디렉토리가 가지고 있고, 그 다음 위치는 실제로 그 위치에 가보면 그 다음 위치를 확인 가능
    - 디스크의 빈 영역이라면 아무곳이나 들어갈 수 있음
- 장점
    - 외부조각 미발생(external fragmentation)
- 단점
    - No random access
        - 디렉토리는 첫번째 블럭의 위치만 알기 때문에, 네번째 블럭에 접근하려면 1->2->3번째 블럭까지 가봐야 알 수 있음
        - 즉, 중간 위치에 접근하려면, 순차 접근이 필요
        - 디스크는 직접 접근이 가능한 매체이나, 관리하는 방법에 따라 직접 접근이 불가능함을 보여줌
        - Disk Head를 자주 옮겨야하기 때문에 overhead가 큼
    - Reliability 문제
        - 한 sector가 고장나 pointer가 유실되면 많은 부분을 잃음
    - Pointer를 위한 공간이 block의 일부가 되어 공간 효율성을 떨어뜨림
        - practical한 문제에 해당
        - 512 bytes/sector, 4 bytes/pointer
            - 512 bytes => 디스크와 컴퓨터 내부에 주고받는 인터페이스가 512 bytes의 배수임을 의미
        - 512 bytes 파일을 하나의 섹터에 저장할 것을, pointer로 인한 4bytes 때문에 두개의 섹터에 걸쳐 저장될 수 있는 문제 발생
- 변형
    - File-allocation table(FAT) 파일 시스템
        - 포인터를 별도의 위치에 보관하여 reliability와 공간 효율성 문제 해결

### Indexed Allocation
- 특징
    - 직접접근이 가능하고자(중간위치에 접근하기 위하여 순차 접근하는 문제를 해결하기 위해) 디렉토리에 파일의 위치정보를 바로 저장하는게 아니라, 먼저 index를 가리키게 함
    - directory가 가지고 있는 block이 index block이기 때문에 실제 파일의 내용을 담는 것이 아닌, 파일이 어디에 저장되어 있는지 위치 정보를 block 하나에 열거해놓는 방식
    - 해당 예시에는 5개의 블럭으로 구성이 되고, 첫번째 블럭이 9, 그다음이 16, 마지막이 25라고 index block 안에 내용으로 적어 놓음
    - 앞에서 4번째 블럭에 접근하려면 순차접근하지 않고, index block만 살펴보면 직접 접근 가능
    - 순차 접근의 hole문제도 비어 있는 곳에 저장하면 되기 때문에 해결 가능
- 장점
    - 외부조각 미발생(external fragmentation)
    - Direct access(=random access) 가능
- 단점
    - Small file의 경우 공간 낭비(실제로 많은 file들이 small)
        - 아무리 작은 블럭이라도 블럭이 2개 필요(index block & 실제 데이터 저장 block)
    - Too Large file의 경우 하나의 block으로 index를 저장하기에 부족
        - 해결방안
            - linked scheme
                - index block에 실제 파일의 위치가 어디 있는지 다 적다가 끝까지 갔는데 파일의 범위를 다 커버하지 못하겠으면, 마지막에 또다른 index block을 가리키도록 설정
            - multi-level index
                - 하나의 index 블럭이 직접 파일의 위치를 가리키는게 아니라 또 다른 index를 가리키게 해서, 2단계 page table 쓰듯, 2번 거쳐야 파일의 위치를 가리키도록 표현 가능 
                - 이또한 index를 위한 공간 낭비 문제 발생 가능


## 실제 File System 사용 예시
실제 file system에서는 어떻게 file 저장 방법을 사용 혹은 변형하는가?

### UNIX 파일시스템 구조

<img src="https://i.imgur.com/q0jX6Hg.png" width="600" height="400">

- 역사가 오래 되었고, 가장 기본적인 파일 시스템 구조
- Partition(논리 디스크)를 4개의 block으로 구성
    - Book block / Super block / Inode list / Data block 순서
- 가장 큰 특징으로는, Inode가 있음
- 파일의 메타데이터는 Inode에 별도로 관리
    
<img src="https://i.imgur.com/56Lz9bk.png" width="600" height="400">

- Boot block
    - 부팅에 필요한 정보(bootstrap loader)
        - 이를 통해 운영체제 커널의 위치를 찾아 정상 부팅 가능
    - 어떤 파일 시스템이든 Boot block이 항상 제일 앞에 나옴(약속)
- Super block
    - 파일 시스템에 관한 총체적인 정보를 담고 있음
    - 즉, 어디가 빈 block이고, 어디가 실제로 파일이 저장된, 사용중인 block인지 관리
    - 어디까지 Inode block이고, 어디부터 Data block인지!
- Inode
    - **파일 이름을 제외한** 파일의 모든 메타 데이터를 저장
        - 파일의 메타데이터는 파일을 담고 있는 디렉토리에 담겨있다 배웠지만, 실제 파일 시스템의 구현에서는 디렉토리가 메타데이터를 다 가지고 있지는 않음
        - UNIX 파일 시스템에서는 디렉토리는 극히 일부분의 메타데이터(파일 이름)를 가지고 있고, 실제 파일의 메타데이터들은 별도의 위치에 보관 
        - 그 위치가 바로 Inode list
            - Inode = Index node
        - 빨간색으로 표시한 Inode 하나당, 파일 하나에 할당
    - 위치 정보 저장을 Index Allocation을 변형해서 사용(거의 그대로 사용)
        - Inode는 크기 고정 -> 포인터 개수 유한
        - 작은 Inode를 가지고도 굉장히 큰 file 또한 표현하기 위해 4가지로 위치 정보 구성
            - 종류
                - direct index
                - single indirect
                - double indirect
                - triple indirect
            - 굉장히 파일 크기 작은 data는 direct index만 가지고 위치정보 표현 가능
            - 파일 크기가 큰 경우, indirect 방법을 사용해 타고 타고 들어가는 방식 
            - 매우 효율적인 방법
                - 대부분의 경우 파일의 크기가 작음
                - 작은 파일들은 한번의 포인터 접근으로 파일 위치 바로 확인 가능
                - 가끔 발생하나, 큰 파일의 경우 index를 디스크에서 추가적으로 접근해서, 파일 위치 확인 가능
- Data block
    - 파일의 실제 내용 보관


### FAT 파일시스템 구조

<img src="https://i.imgur.com/LKPslqn.png" width="600" height="400">

- Partition(논리 디스크)를 4개의 block으로 구성
    - Book block / FAT / Root directory / Data block 순서
        - Book block은 어떤 파일 시스템이던간에 부팅 관련 정보 저장
        - FAT은 파일의 메타데이터 일부 저장
            - 지극히 제한적인 위치 정보만!
            - 나머지는 directory에!
        - 원래 파일의 메타데이터는 디렉토리에만 저장되어 있는데, FAT 파일 시스템의 경우, 파일 이름을 비롯한, 접근권한, 소유주 등 메타데이터를 디렉토리가 다 가지고 있고, 심지어 그 파일의 첫번째 위치가 어딘지 디렉토리가 가지고 있음
- Linked Allocation의 단점 모두 극복
    - Linked Allocation의 경우 첫번째 block이 끝날때, 파일의 크기가 크다면 두번째 블럭의 위치를 저장한다 하였는데, 이로 인하여 bad sector, 512 byte 크기 문제 등이 있었음
    - Random Access & 공간 효율성
        - 이를 해결하고자, 다음 블럭이 무엇인지를 FAT이라는 별도의 table의 배열에 담음
        - 배열의 크기는 디스크가 관리하는 Data block의 개수 만큼
            - n개의 블럭이 있다면 배열의 크기가 n이 됨
        - 배열에는 숫자를 담을 수 있는데, 그 숫자는 그 block의 다음 block이 어딘지 담고 있음
        - 마지막 block에는 파일이 끝났다는 약속된 숫자(EOF)가 적혀있음
        - 즉, FAT 파일 시스템은 Linked Allocation을 활용하여, 다음 위치를 찾기 위해 실제 block에 접근해야 되는 것이 아니라, FAT만 확인해보면 다음 위치를 확인할 수 있음
        - 따라서, FAT 파일 시스템은 직접 접근이 가능
            - Linked Allocation은 직접 접근 불가능
            - FAT은 결국 작은 table로, 이미 메모리에 올라간 상황이고, 그 상황에서 해당 파일의 4번째 블럭을 본다는 의미는 table을 메모리에 올려놓고 쭉 따라가는 것이기 때문에, 곧바로 4번째 블럭의 위치를 파악할 수 있고, 실제 Data block, 디스크에서 2번째, 3번재 블럭을 봐야 알 수 있는게 아니라 바로 알 수 있음을 의미
    - Reliability
        - bad sector가 난다 해도, FAT에 정보가 있기 때문에, Data block과 FAT의 내용이 분리가 되었고, FAT은 중요한 정보이므로, 디스크에 보통 2개의 copy를 두므로 reliability 개선

## Free-Space Management
앞서 파일에 할당된 데이터를 어떻게 관리하는가를 알아보았고, 중간중간 비어있는 블럭을 어떻게 관리할 것인가?
### Bit map or bit vector

<img src="https://i.imgur.com/dEVTJHf.png" width="300" height="150">

- 각각의 block별로, 번호가 있는데, UNIX의 경우, Super block을 예시로, bit를 두어, 사용중인지 비어있는지 0과 1로 표시
    - 0 => 비어 있음
    - 1 => 할당됨
- Bit map의 크기는 block의 개수만큼!
- 파일 시스템이 파일이 새로 만들어지거나 파일의 크기가 커지면 비어있는 블럭을 하나 할당해야하고, 파일이 삭제되면 1로 표시되었던 Bit map을 0으로 변경 
- Bit map은 (디스크의) 부가적인 공간을 필요로 함
    - 단점이라면 단점이나, 그렇게 많은 공간 요구 X
- 연속적인 n개의 free block을 찾는데 효과적
    - 즉, 연속적인 빈 블럭을 찾는데 효과적

### Linked list

<img src="https://i.imgur.com/HJT8aWZ.png" width="600" height="500">

- 비어있는 block의 첫번째 위치만 pointer로 가지고 있음
- 모든 free block들을 링크로 연결(free list)
- 연속적인 가용곤간을 찾는 것은 쉽지 않음
- 공간의 낭비가 없음
- 이론적으로 존재하나, 실제로 사용하기 쉽지 않음
- Linked Allocation을 비슷하게 바꾼 예시

### Grouping

<img src="https://i.imgur.com/diZzoOZ.png" width="300" height="200">

- Indexed Allocation을 비슷하게 바꾼 예시
- Linked list 방법의 변형
- 첫번째 free block이 n개의 pointer를 가짐
    - 처음 빈 위치에는 index의 역할을 해서, 비어있는 block의 포인터가 저장되어 있음
    - n-1 pointer는 free data block을 가리킴
    - 마지막 pointer가 가리키는 block은 또 다시 n pointer를 가짐
- 비어 있는 block을 한꺼번에 찾기에는 linked list보다는 효율적이지만, 그래도 연속적인 빈 block을 찾기에는 효과적이진 않음


### Counting
- 연속적인 빈 block을 찾기에 효과적
- 프로그램들이 종종 여러 개의 연속적인 block을 할당하고 반납한다는 성질에 착안
- (first free lbock, # of contiguous free blocks)을 유지
    - 빈 블럭의 첫번째 위치, 거기서부터 몇개가 빈 블럭인지를 쌍으로 관리
    - Grouping처럼 단순히 빈 블럭을 가리키는 것뿐만 아니라, 거기서부터 몇개가 비어있는지 표시

## Directory Implementation
디렉토리를 어떻게 구현하는가?

### Linear List

<img src="https://i.imgur.com/LH2uJUq.png" width="300" height="200">

- <file name, file의 metadata>의 list
- 구현이 간단
- 디렉토리 내에 파일이 있는지 찾기 위해서는 linear search 필요(time-consuming)
    - 특정 파일이 있는지 찾기 위하여 다 검색하여야 함
- 파일 네임, 메타데이터 크기는 고정되어 있음

### Hash Table
![]()
<img src="https://i.imgur.com/12WXAGQ.png" width="400" height="200">

- linear list + hashing
- Hash table은 file name을 이 파일의 linear list의 위치로 바꾸어줌
    - 파일 이름을 그냥 저장하는게 아니라, hash 함수 적용
    - hash 함수는 어떤 input 값이 주어지더라도, 결과값이 특정 범위의 숫자로 한정됨
- search time을 없앰
    - 파일을 찾기 위해 순차적으로 탐색하지 않고, hash 함수를 적용해, 해시 함수의 결과값에 해당하는 엔트리만 찾아가면 됨
- Collision 발생 가능
    - 해시 함수를 적용했는데 같은 결과값에 나올 수 있는 현상
    - 자료구조에서 해결 방법 궁구 가능

### File의 metadata 보관 위치
- 디렉토리 내 직접 보관
- 디렉토리에는 포인터만 두고 다른 곳에 보관
    - inode, FAT 등

### Long file name의 지원

<img src="https://i.imgur.com/1zs9lNA.png" width="700" height="150">

-  <file name, file의 metadata>의 list에서 각 entry는 일반적으로 고정 크기
-  file name이 고정 크기의 entry 길이보다 길어지는 경우, entry 마지막 부분에 이름의 뒷부분이 위치한 곳의 포인터를 두는 방법
-  이름의 나머지 부분은 동일한 directory file의 일부에 존재

## VFS & NFS

<img src="https://i.imgur.com/PlHiHP4.png" width="600" height="400">

### Virtual File System(VFS)
- 서로 다른 다양한 file system에 대해 동일한 시스템 콜 인터페이스(API)를 통해 접근할 수 있게 해주는 OS의 layer
    - 여러 종류의 file system이 있는데, 사용자가 file system에 접근하기 위해서는 system call 필요
    - file system 종류별로 서로 다른 system call 인터페이스를 사용한다면 사용자 혼란
    - 그래서 개별 file system의 윗 계층에 VFS를 둠

### Network File System(NFS)
- 분산 시스템에서는 네트워크를 통해 파일이 공유될 수 있음
    - 파일 시스템이 local 뿐만 아니라 remote 환경에서 저장될 수도 있음
    - 서버, 클라이언트 모두 NFS 모듈이 필요
- NFS는 분산 환경에서의 대표적인 파일 공유 방법


## Page Cache & Buffer Cache

### Page Cache
- Virtual Memory의 paging system에서 사용하는 page frame(물리적인 메모리에 있는 page)을 caching의 관점에서 설명하는 용어
- Memory-Mapped I/O를 쓰는 경우 file의 I/O에서도 page cache 사용

### Memory-Mapped I/O (파일로 한정시, Memory-Mapped File)
- 기존 파일 접근 방식은 파일을 open한 다음에, read 혹은 write 시스템 콜을 통해 접근
- 이런 방법을 사용하지 않고, File의 일부를 Virtual Memory에 mapping시킴
- 매핑시킨 영역에 대한 메모리 접근 연산은 파일의 입출력을 수행하게 함
    - read / write 시스템 콜을 하지 않고, 메모리에다 읽고 쓰는!
    - 마치, 메모리에 변수를 잡고 데이터를 읽고 쓰는데, 실제로는 파일에 데이터를 읽고 쓰는 것같은 효과

### Buffer Cache
- 파일시스템을 통한 I/O 연산은 메모리의 특정 영역인 buffer cache 사용
- File 사용의 locality 활용
    - 한번 읽어온 block에 대한 후속 요청시 buffer cache에서 즉시 전달
- 모든 프로세스가 공용으로 사용
- Replacement algorithm 필요(LRU, LFU 등)

### Unified Buffer Cache
- 최근의 OS에서는 기존의 buffer cahce가 page cache에 통합됨
- buffer cache도 page 단위로 관리
- 커널 메모리 영역, 사용자 메모리 영역과 같은 공간 구분을 하지 않음 -> 똑같이 page 단위로 관리
- 파일입출력을 위한 공간 필요시, buffer cache 용도로 쓰고, 프로세스의 주소 공간 중 page 필요시, page cache 용도로 씀
- 즉, 별도 구분 미리 하지 않고, 필요시 할당해서 사용

### Page Cache vs Buffer Cache
- Virtual Memory 관점에서는 Page Cache, 파일 시스템 관점에서는 Buffer Cache라 함
- 간단하게 정리하면
    - page cache는 프로세스의 주소 공간을 구성하는 page가 swap area에 내려가 있는가, 혹은 page cache에 올라와 있는가
    - buffer cache는 file 데이터가 file system storage에 저장되어 있는가, 아니면 운영체제의 buffer cache에 올라와 있는가
- Page Cache
    - 운영체제에 주어지는 정보 제한적. 
    - Cache Hit가 발생하면 이미 메모리에 존재하는 데이터에 대하여 하드웨어적 주소 변환만 이루어져 정확한 접근 시간을 알 수 없어 clock 알고리즘 등 사용
    - page cache 단위 = page (4kB)
- Buffer Cache
    - 파일 데이터가 메모리에 있든, 없든간에 어차피 파일에 접근하기 위해서는 시스템 콜이 이루어져, CPU 제어권이 운영체제에 넘어와, 요청이 언제 이루어졌는지 cache hit가 나든, miss가 나든 알 수 있음. 
    - 그 정보를 이용해 LRU, LFU 등의 알고리즘 적용 가능
    - buffer cache 단위 = sector(논리 블럭) (512bytes)

### 추가

<img src="https://i.imgur.com/1LWjOeY.png" width="600" height="400">

- 좌측: 물리적 메모리(커널 영역 & 사용자 메모리 영역) / 우측: 디스크
- 사용자 영역은 page 단위로 필요한 데이터가 올라오고 내려감
- 원래는 커널 메모리 영역에 buffer cache가 존재 했음
- 그래서 파일 내용을 읽어오라 하면, 이것을 buffer cache에 먼저 가져온 후, 사용자에게 전달
- page는 보통 4kB 단위 / 블럭은 보통 512 Byte 단위
- 최근에는 page cache와 buffer cache가 합쳐져, buffer cache도 page와 마찬가지로, 4kB 단위로 블럭을 관리(Unified Buffer Cache 특징)
- 가상 메모리에서 사용하는 Swap area는 빠르게 데이터를 내려놓고 올리고 해야하기 때문에, 여러개의 블럭을 모아 4kB 단위로 올려놓거나 내려놓거나 하는게 기본
- 더 크게 4kB 페이지 하나가 아니라, 여러개의 페이지를 한번에 올리고 내리기도 함
- 이는 속도 효율성을 위해!

<img src="https://i.imgur.com/SRocTSC.png" width="600" height="400">

- #### 기존 buffer cache 환경
    - 기존 파일 데이터를 읽고 쓰는 방식은 2가지 방법 존재
        1) 파일을 open한 다음, read/write system call
            - 운영체제가 해당 파일 내용이 buffer cache에 있으면 전달해주고, 없으면 disk file system에서 읽어와서 전달
        2) memory-mapped I/O 방식
            - 처음에는 memory-mapped I/O를 쓰겠다는 시스템 콜 발생
            - 자신의 주소 공간 중 일부를 file에 mapping
            - mapping을 해도, 디스크에 파일을 읽어오는 것은 똑같음
            - 즉, buffer cache에 읽어오는 것까진 똑같은데, 그런 다음에 page cache에 내용을 copy
            - 이 copy한 내용이 file의 mapped된 내용이 됨
            - 지금부터는 사용자 프로그램이 자신의 page cache(mmap된 영역)에 데이터를 메모리에 읽고 쓰듯이 요청하면, 그게 read/write가 됨
            - 운영체제의 간섭없이 내 메모리영역에다가 데이터를 읽거나 쓰는, 그냥 메모리 접근하는 방식을 통해 파일 입출력을 하게 됨
            - mmap만 해놓았지, 내용을 memory로 안 읽어왔다면, page cache를 접근하고자 할때 page fault가 발생
            - 기존 가상 메모리 관리와 동일
            - page fault가 발생하면, page fault handler가 발생해 운영체제로 CPU가 넘어가, 파일 시스템 내용을 메모리로 읽어 놓고 쓰게 됨
            - mmap된 내용이, 메모리 영역에 올라와있다면, 그때부터는 커널의 도움 없이 자신의 메모리 영역에 직접 읽고 쓰고 함
    - 진행하는 방법은 똑같으나, 차이점으로 read/write 시스템 콜을 쓸 때는, 그 내용이 buffer cache에 있든, 없든간에 항상 운영체제에게 요청을 해서, 받아와야 되는 것이고, mmap을 쓰면 일단 page cache에 올라온 내용은 운영체제의 도움을 받지 않고, 사용자 프로세스가 직접 자기의 주소 공간에 맵핑된 것이니 메모리 접근하는 방식을 통해 I/O를 하게 됨
    - 즉, mmap을 특별히 쓰는 이유는 이미 메모리에 올라온 내용에 대해서 커널의 도움을 받지 않고, 자신이 직접 자신의 메모리를 접근하듯이 읽고 쓸 수 있기 때문
    - 기존 버퍼 캐시 환경에서는 어떤 방법을 쓰든, 파일 입출력을 할때는 buffer cache를 통과해야함
    - 그래서, 양쪽 모두 buffer cache에 있는 내용을 자신의 page cache에 복제해야하는 overhead 발생
- #### Unified buffer cache 환경
    - 운영체제가 메모리 영역을 구분하지 않고 필요에 따라 page cache를 이용해 공간을 사용하니, 경로가 단순해짐
        1) 파일을 open한 다음, read/write system call
            - 먼저, 운영체제에게 system call로 인해 CPU 제어권 넘어감
            - 운영체제는 이미 메모리에 올라와 있는 내용은 사용자 프로그램의 주소 영역에 단순 copy 전달
            - 메모리에 올라와 있지 않은 내용은 디스크의 파일 시스템에서 읽어와 사용자 프로그램에게 copy 전달
        2) memory-mapped I/O 방식
            - 처음 운영체제에게 자신의 주소영역 일부를 파일에 mapping
            - 사용자 프로그램 주소 영역에 page cache가 mapping됨
            - 기존 buffer cache 환경과 달리, buffer cache 내용을 한번더 copy해서 올라가는게 아니고, page cache 자체가 사용자 프로세스의 논리적인 주소 영역에 mapping됨
            - 그래서 page cache에 직접 읽고 쓰기 가능
            - page cache, buffer cache가 별도로 존재하는게 아니라 share되서 쓰기 때문

### 파일을 프로그램의 주소 영역에 mapping해서 쓰는 사례
#### 실행파일

<img src="https://i.imgur.com/IXXwJlu.png" width="600" height="400">

- 프로그램이 file system에서 실행 파일 형태로 저장됨
- 실행파일을 실행시키면 프로세스가 됨
- 프로세스가 되면 그 프로세스만의 독자적인 주소 공간 virtual memory가 만들어짐
    - code, data, stack으로 구성되는 독자적인 주소 공간
- 주소 변환(Address translation)을 해주는 하드웨어를 통해, 메모리에서 당장 필요한 부분은 물리적인 메모리에 올라가게 됨
- 물리적인 메모리 공간이 한정되어 있기 때문에, 쫓겨나는 것들은 disk의 swap area로 넘어감 

- code부분은 메모리에 올라간 다음에, 쫓겨날때 swap area로 내려가지 않음
- code부분은 read-only로, 파일 시스템의 실행 파일에 저장되어 있는데, 이 코드의 일부가 메모리에 올라갔다 쫓겨날때는 swap 영역에 써줄 필요가 없음
- 이미, file system의 실행 파일에 있기 때문

- memory-mapped I/O는 사용자 프로그램이 프로그램을 작성해서 프로그램 도중에 파일의 내용을 읽어와라 할때도 기본적으로 memory-mapped I/O를 쓸 수 있지만, 실제로 실행파일을 실행시킬때, loader란 소프트웨어가 해당 프로그렘을 메모리에 올려놓을때 memory-mapped file을 쓰는 대표적인 방법이 실행파일에 해당하는 code부분
- code부분은 별도의 swap area 부분을 가지고 있지 않고, 파일 시스템의 파일 형태로 존재하는 내용이 그대로 프로세스의 주소 영역(Code)에 mapping이 되는 형태임
- 주소공간에 mapping이 되어 있기 때문에, 만약 이 프로그램이 특정 code를 접근하는데 메모리에 올라와 있지 않은 경우 swap 영역에서 올리는게 아니라, 파일 시스템의 실행 파일에 있는 것을 올려야 함

#### 데이터 파일

<img src="https://i.imgur.com/OBF24ht.png" width="600" height="400">

- 실행 파일도 파일 시스템에 저장되어 있겠지만, 데이터 파일도 저장되어 있을 것임
- 프로그램이 실행이 되다가 자신의 주소공간, 즉 메모리 접근만 하는게 아니라 파일을 읽어오라는 read system call을 할 수도, 데이터 파일에 접근하기 위해 memory-mapped I/O를 써서 접근할 수도 있음

<img src="https://i.imgur.com/IHzrThj.png" width="600" height="400">

- B 실행파일을 쓰다가 검은색 데이터 파일을 쓰고 싶은데, memory-mapped I/O 방식으로 쓰고 싶다면, 운영체제에게 이 데이터 파일의 일부를 자신의 주소 공간 일부에 mapping 해달라고 mmap() 시스템 콜 발생

<img src="https://i.imgur.com/h2hQy3C.png" width="600" height="400">

- 그러면 운영체제가 이를 수용하여, 데이터 파일의 일부를 프로그램의 주소 공간 일부에 mapping해놓음
- 프로그램이 실행되면서 검은색 메모리 위치에 접근했을때, 만약 그 내용이 메모리에 안 올라와 있다면, page fault 발생
- page fault로 CPU가 OS로 넘어가 page fault가 발생한 page를 물리적 메모리에 올려 놓음
- 이후, 가상 page가 물리적인 page로 mapping 됨
- 그러면, 프로세스 B가 데이터 파일의 메모리에 올라온 부분을 접근할 때는 OS의 도움을 받지 않고, 자신의 주소공간 중 일부에 있기 때문에, 물리적 메모리에서 데이터를 읽거나 쓰거나 가능
- 나중에 물리적 메모리에 있는 검은 부분이 쫓겨날 때는, swap area에 쓰는게 아니라, memory mapped file이기 때문에, file에 수정된 내용을 써주고 쫓아내야함

<img src="https://i.imgur.com/m3rbyv2.png" width="600" height="400">

- 데이터 파일에 대하여, memory-mapped I/O 방식이 아닌 system call 방식을 사용하면, 운영체제는 자신의 buffer cache에 데이터 파일 내용을 읽어오는데, unified buffer cache의 물리적 메모리의 검은 부분이 page cache이고, 프로세스 B에서 맵핑되어있지만, 또한 이거는 buffer cache를 겸하고 있음

<img src="https://i.imgur.com/UjyfrIz.png" width="600" height="400">

- 그래서 read system call을 했는데, 실행파일 A가 요청한 데이터파일의 내용이 page cache, 즉 buffer cache에 올라와 있다면, 그 내용을 copy 해서, 사용자 프로세스에 전달해주어야 함

#### 정리
- 사용자 프로그램이 파일을 접근하는 방식은 인터페이스가 read/write system call과 memory-mapped I/O를 이용하는 방식이 존재
- read/write system call을 이용하게 되면 cache에 있는 내용을 copy해서 프로세스의 주소 공간에 전달
- memory-mapped I/O를 이용하게 되면, copy 해서 전달하는게 아니라, 그냥 mapping 해서 쓰는 것으로 프로세스 주소 공간의 내용이 곧 물리 메로리 내용과 동일. 
- 즉, 논리 페이지가 프레임에 올라와 있음. 
- 따라서, 메모리에 올라온 파일의 내용은 시스템 콜을 하지 않고, 자신이 CPU를 가지고 있으면서 직접 접근할 수 있기 때문에 더 빠른 장점이 있음.
- Cache에 올라온 내용을 자신의 주소공간으로 copy해오는 overhead가 없이, 변경 사항이 그대로 mapping됨. 
- 장점은 메모리 copy가 줄어들고, 이미 메모리에 올라온 내용은 운영체제의 도움이 필요없음
- 단점으로 page(buffer) cache를 mapping한 것이기 때문에 다른 프로세스도 mmap을 써서 share해서 사용하게 되면 일관성 문제 발생
    - read/write system call은 copy기 때문에 일관성 유지

---
#### 참고 링크
- [반효경 교수님 강의 - File Systems](https://core.ewha.ac.kr/publicview/C0101020140516150939191200?vmode=f)
- [반효경 교수님 강의 - File Systems Implementation 1](https://core.ewha.ac.kr/publicview/C0101020140520134614002164?vmode=f)
- [반효경 교수님 강의 - File Systems Implementation 2](https://core.ewha.ac.kr/publicview/C0101020140523142954456205?vmode=f)

